{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Melanoma classification </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Imports </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.applications import VGG16\n",
    "from keras import models, layers, optimizers, regularizers\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ReduceLROnPlateau , ModelCheckpoint, EarlyStopping\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import recall_score\n",
    "from pathlib import Path\n",
    "import os, shutil\n",
    "import numpy as np\n",
    "from skimage import exposure,color,io,transform,filters,util\n",
    "from keras import backend as K\n",
    "import pandas as pd\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Data directories </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = Path('D:/DATASETS/MELANOMA')\n",
    "\n",
    "train_dir = data_dir / 'train'\n",
    "\n",
    "test_dir = data_dir / 'test'\n",
    "\n",
    "train_csv_dir = data_dir / 'train_csv'\n",
    "\n",
    "test_csv_dir = data_dir / 'test_csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Structured data load and preprocessing </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(data_dir / 'train.csv')\n",
    "test = pd.read_csv(data_dir / 'test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(data_dir / 'train.csv')\n",
    "test = pd.read_csv(data_dir / 'test.csv')\n",
    "\n",
    "train.drop(['benign_malignant', 'patient_id', 'diagnosis'], axis=1, inplace=True)\n",
    "test.drop('patient_id', axis=1, inplace=True)\n",
    "\n",
    "train['anatom_site_general_challenge'].fillna('Not_especified', inplace=True)\n",
    "test['anatom_site_general_challenge'].fillna('Not_especified', inplace=True)\n",
    "train.dropna(inplace=True)\n",
    "test.dropna(inplace=True)\n",
    "\n",
    "train = pd.get_dummies(train, columns=['sex', 'anatom_site_general_challenge'])\n",
    "test = pd.get_dummies(test, columns=['sex', 'anatom_site_general_challenge'])\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(train['age_approx'].values.reshape(-1,1))\n",
    "\n",
    "train['age_approx'] = scaler.transform(train['age_approx'].values.reshape(-1,1))\n",
    "test['age_approx'] = scaler.transform(test['age_approx'].values.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Elimino imagenes con Nan </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for fname in os.listdir(train_dir / 'BENIGN'):\n",
    "    \n",
    "#     img_name = fname[:-4]\n",
    "    \n",
    "#     if img_name not in train.image_name.values:\n",
    "        \n",
    "#         os.remove(train_dir / 'BENIGN' / fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Separo las imagenes de entrenamiento seg√∫n el target: benigno o maligno </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# directories = [train_dir, test_dir]\n",
    "\n",
    "# for direct in directories:\n",
    "    \n",
    "#     for fname in os.listdir(direct):\n",
    "        \n",
    "#         if fname not in [\"BENIGN\", \"MALIGN\"]:\n",
    "\n",
    "#             src = direct / fname\n",
    "\n",
    "#             if fname[:-4] in train[train[\"target\"] == 0][\"image_name\"].values:\n",
    "\n",
    "#                 dst = direct / 'BENIGN' / fname\n",
    "#                 shutil.move(src,dst)\n",
    "\n",
    "#             if fname[:-4] in train[train[\"target\"] == 1][\"image_name\"].values:\n",
    "\n",
    "#                 dst = direct / 'MALIGN' / fname\n",
    "#                 shutil.move(src,dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "      <th>age_approx</th>\n",
       "      <th>target</th>\n",
       "      <th>sex_female</th>\n",
       "      <th>sex_male</th>\n",
       "      <th>anatom_site_general_challenge_Not_especified</th>\n",
       "      <th>anatom_site_general_challenge_head/neck</th>\n",
       "      <th>anatom_site_general_challenge_lower extremity</th>\n",
       "      <th>anatom_site_general_challenge_oral/genital</th>\n",
       "      <th>anatom_site_general_challenge_palms/soles</th>\n",
       "      <th>anatom_site_general_challenge_torso</th>\n",
       "      <th>anatom_site_general_challenge_upper extremity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ISIC_2637011</td>\n",
       "      <td>-0.269122</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ISIC_0015719</td>\n",
       "      <td>-0.269122</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ISIC_0052212</td>\n",
       "      <td>0.078579</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ISIC_0068279</td>\n",
       "      <td>-0.269122</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ISIC_0074268</td>\n",
       "      <td>0.426281</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     image_name  age_approx  target  sex_female  sex_male  \\\n",
       "0  ISIC_2637011   -0.269122       0           0         1   \n",
       "1  ISIC_0015719   -0.269122       0           1         0   \n",
       "2  ISIC_0052212    0.078579       0           1         0   \n",
       "3  ISIC_0068279   -0.269122       0           1         0   \n",
       "4  ISIC_0074268    0.426281       0           1         0   \n",
       "\n",
       "   anatom_site_general_challenge_Not_especified  \\\n",
       "0                                             0   \n",
       "1                                             0   \n",
       "2                                             0   \n",
       "3                                             0   \n",
       "4                                             0   \n",
       "\n",
       "   anatom_site_general_challenge_head/neck  \\\n",
       "0                                        1   \n",
       "1                                        0   \n",
       "2                                        0   \n",
       "3                                        1   \n",
       "4                                        0   \n",
       "\n",
       "   anatom_site_general_challenge_lower extremity  \\\n",
       "0                                              0   \n",
       "1                                              0   \n",
       "2                                              1   \n",
       "3                                              0   \n",
       "4                                              0   \n",
       "\n",
       "   anatom_site_general_challenge_oral/genital  \\\n",
       "0                                           0   \n",
       "1                                           0   \n",
       "2                                           0   \n",
       "3                                           0   \n",
       "4                                           0   \n",
       "\n",
       "   anatom_site_general_challenge_palms/soles  \\\n",
       "0                                          0   \n",
       "1                                          0   \n",
       "2                                          0   \n",
       "3                                          0   \n",
       "4                                          0   \n",
       "\n",
       "   anatom_site_general_challenge_torso  \\\n",
       "0                                    0   \n",
       "1                                    0   \n",
       "2                                    0   \n",
       "3                                    0   \n",
       "4                                    0   \n",
       "\n",
       "   anatom_site_general_challenge_upper extremity  \n",
       "0                                              0  \n",
       "1                                              1  \n",
       "2                                              0  \n",
       "3                                              0  \n",
       "4                                              1  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Calculo los pesos </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "class_weights = {0:1, 1:56}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Creo el generador de datos </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mixed_data_generator(image_dir, csv_dir, batch_size):\n",
    "    \n",
    "    i = 0\n",
    "    image_file_list = os.listdir(image_dir)\n",
    "    \n",
    "    while True:\n",
    "        \n",
    "        batch_x = {'images': list(), 'other_feats': list()}  # use a dict for multiple inputs\n",
    "        batch_y = list()\n",
    "        \n",
    "        for b in range(batch_size):\n",
    "            \n",
    "            if i == len(image_file_list):\n",
    "                i = 0\n",
    "                random.shuffle(image_file_list)\n",
    "                \n",
    "            image_file_path = image_file_list[i]\n",
    "            csv_file_path = os.path.join(csv_dir, os.path.basename(image_file_path).replace('.jpg', '.csv'))\n",
    "            \n",
    "            i += 1\n",
    "            \n",
    "            image = procesar_imagenes(cv2.imread(os.path.join(image_dir, os.path.basename(image_file_path))))\n",
    "            image = cv2.resize(image, (128,128))\n",
    "            csv_file = pd.read_csv(csv_file_path)\n",
    "            \n",
    "            batch_y.append(csv_file['target'].values)\n",
    "            csv_file.drop('target', axis=1, inplace=True)\n",
    "            other_feat = csv_file.values.reshape(-1,1)\n",
    "            batch_x['images'].append(image)\n",
    "            batch_x['other_feats'].append(other_feat)\n",
    "\n",
    "        batch_x['images'] = np.array(batch_x['images'])\n",
    "        batch_x['other_feats'] = np.array(batch_x['other_feats'])\n",
    "        batch_y = np.array(batch_y)\n",
    "\n",
    "        \n",
    "        \n",
    "        yield [batch_x['other_feats'].reshape(batch_size,10), batch_x['images']], batch_y.reshape(batch_size,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "train_generator = mixed_data_generator(train_dir, train_csv_dir, batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Creo el modelo para datos estructurados </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 32)                352       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 16)                64        \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 16)                0         \n",
      "=================================================================\n",
      "Total params: 1,072\n",
      "Trainable params: 976\n",
      "Non-trainable params: 96\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "mlp_model = models.Sequential()\n",
    "\n",
    "mlp_model.add(layers.Dense(32, kernel_initializer='glorot_normal', kernel_regularizer=regularizers.l2(0.001), input_shape=(10,)))\n",
    "mlp_model.add(layers.BatchNormalization())\n",
    "mlp_model.add(layers.Activation('relu'))\n",
    "\n",
    "mlp_model.add(layers.Dense(16, kernel_initializer='glorot_normal', kernel_regularizer=regularizers.l2(0.001)))\n",
    "mlp_model.add(layers.BatchNormalization())\n",
    "mlp_model.add(layers.Activation('relu'))\n",
    "\n",
    "mlp_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Creo el modelo convolucional </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 128, 128, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 128, 128, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 128, 128, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 64, 64, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 64, 64, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 64, 64, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 32, 32, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 32, 32, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 32, 32, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 32, 32, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 16, 16, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 16, 16, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 16, 16, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 8, 8, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 8, 8, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 8, 8, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 8, 8, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 4, 4, 512)         0         \n",
      "=================================================================\n",
      "Total params: 14,714,688\n",
      "Trainable params: 14,714,688\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "conv_base = VGG16(weights='imagenet',\n",
    "                  include_top=False,\n",
    "                  input_shape=(128,128,3))\n",
    "conv_base.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "vgg16 (Model)                (None, 4, 4, 512)         14714688  \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 8192)              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 512)               4194816   \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 256)               1024      \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 128)               512       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 128)               0         \n",
      "=================================================================\n",
      "Total params: 19,077,312\n",
      "Trainable params: 4,360,832\n",
      "Non-trainable params: 14,716,480\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "conv_model = models.Sequential()\n",
    "\n",
    "conv_model.add(conv_base)\n",
    "\n",
    "conv_model.add(layers.Flatten())\n",
    "\n",
    "conv_model.add(layers.Dense(512, kernel_initializer='glorot_normal', kernel_regularizer=regularizers.l2(0.001)))\n",
    "conv_model.add(layers.BatchNormalization())\n",
    "conv_model.add(layers.Activation('relu'))\n",
    "\n",
    "conv_model.add(layers.Dropout(0.4))\n",
    "\n",
    "conv_model.add(layers.Dense(256, kernel_initializer='glorot_normal', kernel_regularizer=regularizers.l2(0.001)))\n",
    "conv_model.add(layers.BatchNormalization())\n",
    "conv_model.add(layers.Activation('relu'))\n",
    "\n",
    "conv_model.add(layers.Dropout(0.2))\n",
    "\n",
    "conv_model.add(layers.Dense(128, kernel_initializer='glorot_normal'))\n",
    "conv_model.add(layers.BatchNormalization())\n",
    "conv_model.add(layers.Activation('relu'))\n",
    "\n",
    "conv_base.trainable = False\n",
    "\n",
    "conv_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 144)\n"
     ]
    }
   ],
   "source": [
    "combinedInput = layers.Concatenate()([mlp_model.output, conv_model.output])\n",
    "\n",
    "print(combinedInput.shape)\n",
    "\n",
    "x = layers.Dense(256, kernel_initializer='glorot_normal', kernel_regularizer=regularizers.l2(0.001))(combinedInput)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Activation('relu')(x)\n",
    "\n",
    "x = layers.Dropout(0.4)(x)\n",
    "\n",
    "x = layers.Dense(128, kernel_initializer='glorot_normal', kernel_regularizer=regularizers.l2(0.001))(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Activation('relu')(x)\n",
    "\n",
    "x = layers.Dropout(0.4)(x)\n",
    "\n",
    "x = layers.Dense(64, kernel_initializer='glorot_normal', kernel_regularizer=regularizers.l2(0.001))(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Activation('relu')(x)\n",
    "\n",
    "x = layers.Dense(1, kernel_initializer='glorot_normal', activation='sigmoid')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Model(inputs=[mlp_model.input, conv_model.input], outputs=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = optimizers.RMSprop(learning_rate=1e-5, rho=0.9)\n",
    "\n",
    "lr_reduce = ReduceLROnPlateau(monitor='accuracy', factor=0.1, min_delta=0.001, patience=5, cooldown=3, verbose=1)\n",
    "\n",
    "early_stop = EarlyStopping(monitor='accuracy', mode='max', patience=10, verbose=1)\n",
    "\n",
    "filepath=\"melanoma_v1.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='accuracy', verbose=1, save_best_only=True, mode='max')\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "model.fit_generator(train_generator,\n",
    "                    class_weight=class_weights,\n",
    "                    steps_per_epoch=1033,\n",
    "                    epochs=5,\n",
    "                    callbacks=[lr_reduce,checkpoint,early_stop])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu",
   "language": "python",
   "name": "gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
